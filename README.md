# ðŸ“š Quiz\_LLM â€” Chatbot RAG basado en PDF con LangChain y Ollama

Este proyecto implementa un **chatbot de preguntas y respuestas basado en PDF**, utilizando **RAG (Retrieval-Augmented Generation)**. Aprovecha tecnologÃ­as de Ãºltima generaciÃ³n como:

* ðŸ§  **LangChain** + **Ollama** para generaciÃ³n de respuestas contextuales
* ðŸ’‚ï¸ **ChromaDB** para almacenamiento vectorial
* ðŸŒ **Streamlit** como interfaz grÃ¡fica
* ðŸ’ª **LangSmith** para trazabilidad y depuraciÃ³n

---

## ðŸš€ Requisitos

* Python **3.12+**
* [Ollama](https://ollama.com) instalado y ejecutÃ¡ndose localmente
* [uv](https://github.com/astral-sh/uv) instalado (`pip install uv`)
* `.env` con variable `LANGCHAIN_PROJECT`

---

## âš™ï¸ InstalaciÃ³n

1. **Clona el repositorio:**

   ```bash
   git clone https://github.com/tu-usuario/Quiz_LLM.git
   cd Quiz_LLM
   ```

2. **Instala dependencias y crea entorno:**

   ```bash
   uv venv
   source .venv/bin/activate  # En Windows: .venv\Scripts\activate
   uv pip install -r requirements.txt
   ```

   O directamente con `uv` y el `pyproject.toml`:

   ```bash
   uv pip install -e .
   ```

3. **Configura el entorno:**

   Crea un archivo `.env` en la raÃ­z:

   ```env
   LANGCHAIN_PROJECT=NombreDeTuProyectoLangSmith
   ```

4. **AsegÃºrate de que Ollama estÃ© corriendo:**

   ```bash
   ollama run llama3
   ```

---

## â–¶ï¸ Ejecutar la aplicaciÃ³n

Utiliza el `Makefile` para ejecutar la app:

```bash
make app
```

Esto ejecutarÃ¡ internamente:

```bash
uv run streamlit run app.py
```

La interfaz se abrirÃ¡ en tu navegador para cargar PDFs y hacer preguntas.

---

## ðŸ“œ Estructura del Proyecto

```
Quiz_LLM/
â”œâ”€â”€ scr/
â”‚   â”œâ”€â”€ app.py             # Interfaz principal (Streamlit)
â”‚   â”œâ”€â”€ rag.py             # LÃ³gica de carga y RAG
â”‚   â”œâ”€â”€ data/              # PDFs subidos (excluido en .gitignore)
â”‚   â””â”€â”€ chroma/            # Vector store persistente
â”œâ”€â”€ data/                  # Carpeta raÃ­z para PDFs
â”œâ”€â”€ .env                   # Variables de entorno (no subir)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```

---

## ðŸ›† Dependencias

Las dependencias estÃ¡n gestionadas desde `pyproject.toml`:

```toml
[project]
name = "quiz"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "chromadb>=1.0.9",
    "community>=1.0.0b1",
    "dotenv>=0.9.9",
    "langchain>=0.3.25",
    "langchain-chroma>=0.2.4",
    "langchain-community>=0.3.24",
    "langchain-ollama>=0.3.3",
    "langsmith>=0.3.42",
    "ollama>=0.4.8",
    "pypdf>=5.5.0",
    "streamlit>=1.45.1",
]
```

---



